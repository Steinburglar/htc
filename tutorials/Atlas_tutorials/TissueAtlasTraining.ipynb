{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tissue Atlas Model Training Walkthrough\n",
    "This notebook will walk a user through using the Atlas compatible htc for training their own segmentation model. If you have not yet, please read the Setup tutorial for important information.\n",
    "\n",
    "Start with necessary inputs and define path to your dataset_settings .json. The tutorial is written with a very small dataset (2 pigs) called \"HeiPorSpectral_mod\". Replace relevant directory paths / names with the names to your own dataset and json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import JSON\n",
    "from typing import TYPE_CHECKING, Any, Callable, Union, Self\n",
    "from htc import (\n",
    "    Config,\n",
    "    DataPath,\n",
    "    DataSpecification,\n",
    "    MetricAggregation,\n",
    "    SpecsGeneration,\n",
    "    create_class_scores_figure,\n",
    "    settings,\n",
    ")\n",
    "from htc.models.data.SpecsGenerationAtlas import SpecsGenerationAtlas\n",
    "\n",
    "dataset_settings = Path(\"~/dkfz/htc/tests/test_4june/externals/testdataset_Settings.json\")\n",
    "data_dir = settings.data_dirs.test_dataset4june"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can specify important parameters for your training run, such as fold, train/test split, etc. replace the values in the following code block with the values of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filters = [] #list of callable filter functions, can be a variety of things\n",
    "annotation_name = None #name of annotators to be used\n",
    "test_ratio = 0 #ratio of images to be saved as test, i.e, not ued in any training. should be float between 0.0 and 1.0\n",
    "n_folds = 2 #number of folds to make in the training data. training data (not test data) will be randomly split into n_folds different groups\n",
    "#for each \"fold\", the network will train a model with one of the groups as validation and all the other groups as training data.  \n",
    "seed = None #optional parameter that interacts with the random grouping of the folding operation. For a different fold upon every function call, set = None.\n",
    "# for a consistent fold, set seed to a number of your choice, e.g. seed = 42\n",
    "name = \"Atlas\" #name of a json file created in the following code block, that gets stored in the parent directory of this notebook. name it something simple and descriptive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_dir = Path().absolute()\n",
    "\n",
    "SpecsGenerationAtlas(data_dir,\n",
    "                dataset_settings,\n",
    "                filters = filters,\n",
    "                annotation_name = annotation_name,\n",
    "                test_ratio = test_ratio,\n",
    "                n_folds = n_folds,\n",
    "                seed = seed,\n",
    "                name = name,\n",
    "                ).generate_dataset(target_folder=tutorial_dir)\n",
    "specs_path = tutorial_dir / name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightning Class\n",
    "\n",
    "Next step is to choose/build our lightning class. The Lightning class (as in Pytorch Lightning) performs many aspects of managing training, and can b customized by creating your own child class. most notably, the Lightning class allows you to specify your Loss function.\n",
    "\n",
    "For this walkthrough, we will use the htc default \"LightingImage\" class, which is their default class for training on full images (as opposed to patches, pixels, or superpixels). This calculates loss as a weighted average of Dice loss and Cross-Entropy loss. See the htc \"networkTraining\" tutorial for more info on the lightning class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "The last step before training is to create our configuration file. This file is also a json that contains important metadata, and it is used by the training process itself to configure training hyperparameters, like batch size and transformations. We will use the htc's Config ***class*** to write the config ***json***\n",
    "\n",
    "The following Code block will write the config json for you. By default, it will store the config.json file in the same directory as your dataset_settings json.\n",
    "\n",
    "The following code block is still set up for tutorial use, not production use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "config_name": "default",
       "dataloader_kwargs": {
        "batch_size": 5,
        "num_workers": 1
       },
       "inherits": "models/image/configs/default",
       "input": {
        "annotation_name": [
         "polygon#annotator1",
         "polygon#annotator2",
         "polygon#annotator3"
        ],
        "data_spec": "/home/lucas/dkfz/htc/tutorials/Atlas_tutorials/Atlas",
        "epoch_size": 500,
        "merge_annotations": "union",
        "n_channels": 100,
        "preprocessing": "L1",
        "transforms_gpu": [
         {
          "class": "KorniaTransform",
          "degrees": 45,
          "p": 0.5,
          "padding_mode": "reflection",
          "scale": [
           0.9,
           1.1
          ],
          "transformation_name": "RandomAffine",
          "translate": [
           0.0625,
           0.0625
          ]
         },
         {
          "class": "KorniaTransform",
          "p": 0.25,
          "transformation_name": "RandomHorizontalFlip"
         },
         {
          "class": "KorniaTransform",
          "p": 0.25,
          "transformation_name": "RandomVerticalFlip"
         }
        ]
       },
       "label_mapping": "htc.settings_seg>label_mapping",
       "lightning_class": "htc.models.image.LightningImage>LightningImage",
       "model": {
        "architecture_kwargs": {
         "encoder_name": "efficientnet-b5",
         "encoder_weights": "imagenet"
        },
        "architecture_name": "Unet",
        "model_name": "ModelImage"
       },
       "optimization": {
        "lr_scheduler": {
         "gamma": 0.99,
         "name": "ExponentialLR"
        },
        "optimizer": {
         "lr": 0.001,
         "name": "Adam",
         "weight_decay": 0
        }
       },
       "swa_kwargs": {
        "annealing_epochs": 0
       },
       "trainer_kwargs": {
        "accelerator": "gpu",
        "devices": 1,
        "enable_progress_bar": false,
        "max_epochs": 1,
        "precision": "16-mixed"
       },
       "validation": {
        "checkpoint_metric": "dice_metric",
        "checkpoint_metric_mode": "class_level",
        "dataset_index": 0
       }
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config.from_model_name(\"default\", \"image\")\n",
    "config[\"inherits\"] = \"models/image/configs/default\"\n",
    "config[\"input/data_spec\"] = specs_path\n",
    "config[\"input/annotation_name\"] = [\"polygon#annotator1\", \"polygon#annotator2\", \"polygon#annotator3\"]\n",
    "config[\"validation/checkpoint_metric_mode\"] = \"class_level\"\n",
    "\n",
    "\n",
    "\n",
    "# We want to merge the annotations from all annotators into one label mask\n",
    "config[\"input/merge_annotations\"] = \"union\"\n",
    "\n",
    "# We have a two-class problem and we want to ignore all unlabeled pixels\n",
    "# Everything which is >= settings.label_index_thresh will later be considered invalid\n",
    "#config[\"label_mapping\"] = {\n",
    "#    \"spleen\": 0,\n",
    "#    \"gallbladder\": 1,\n",
    "#    \"unlabeled\": settings.label_index_thresh,\n",
    "#}\n",
    "\n",
    "# Reduce the training time\n",
    "config[\"trainer_kwargs/max_epochs\"] = 1\n",
    "\n",
    "# Progress bars can cause problems in Jupyter notebooks so we disable them here (training does not take super long)\n",
    "config[\"trainer_kwargs/enable_progress_bar\"] = False\n",
    "\n",
    "# Uncomment the following lines if you want to use one of the pretrained models as basis for our training\n",
    "# config[\"model/pretrained_model\"] = {\n",
    "#     \"model\": \"image\",\n",
    "#     \"run_folder\": \"2022-02-03_22-58-44_generated_default_model_comparison\",\n",
    "#\n",
    "\n",
    "config_path = dataset_settings.parent/ (name + \"_config.json\")\n",
    "config.save_config(config_path)\n",
    "JSON(config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Training\n",
    "You are now ready to train your network. Simply run the `htc training` command and pass the model type (image model in our case) and path to the config as arguments.\n",
    "> &#x26a0;&#xfe0f; Starting a training session in a Jupyter notebook is usually not a good idea. Instead, it is advisable to use a [`screen`](https://linuxize.com/post/how-to-use-linux-screen/) environment so that your training runs in the background and you can return later to check for the status.\n",
    "\n",
    "> There is also a `--fold FOLD_NAME` switch if you only want to train only one fold. This is useful for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated Memory: 5143.00 MB\n",
      "Total Memory: 6143.69 MB\n",
      "0\n",
      "_build_cache was acessed\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m The environment variable                          \u001b[2mDatasets.py:125\u001b[0m\n",
      "PATH_Tivita_Cat_atlas_kidney_nativ was set to                    \u001b[2m               \u001b[0m\n",
      "\u001b[35m/home/lucas/dkfz/htc/tests/test_31may/\u001b[0m\u001b[95mCat_atlas_kidney_nativ\u001b[0m but \u001b[2m               \u001b[0m\n",
      "the path does not exist                                          \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Starting training of the fold fold_1 \u001b[1m[\u001b[0m\u001b[37m1\u001b[0m/\u001b[37m2\u001b[0m\u001b[1m]\u001b[0m       \u001b[2mrun_training.py:301\u001b[0m\n",
      "_build_cache was acessed\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m The environment variable                          \u001b[2mDatasets.py:125\u001b[0m\n",
      "PATH_Tivita_Cat_atlas_kidney_nativ was set to                    \u001b[2m               \u001b[0m\n",
      "\u001b[35m/home/lucas/dkfz/htc/tests/test_31may/\u001b[0m\u001b[95mCat_atlas_kidney_nativ\u001b[0m but \u001b[2m               \u001b[0m\n",
      "the path does not exist                                          \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m The following config will be used for training:   \u001b[2mrun_training.py:81\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m \u001b[1m{\u001b[0m\u001b[90m'config_name'\u001b[0m: \u001b[90m'Atlas_config'\u001b[0m,                   \u001b[2mrun_training.py:82\u001b[0m\n",
      " \u001b[90m'dataloader_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'batch_size'\u001b[0m: \u001b[37m5\u001b[0m, \u001b[90m'num_workers'\u001b[0m: \u001b[37m1\u001b[0m\u001b[1m}\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'annotation_name'\u001b[0m: \u001b[1m[\u001b[0m\u001b[90m'\u001b[0m\u001b[36mpolygon#annotator1\u001b[0m\u001b[90m'\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'\u001b[0m\u001b[36mpolygon#annotator2\u001b[0m\u001b[90m'\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'\u001b[0m\u001b[36mpolygon#annotator3\u001b[0m\u001b[90m'\u001b[0m\u001b[1m]\u001b[0m,         \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'data_spec'\u001b[0m:                                       \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'/home/lucas/dkfz/htc/tutorials/Atlas_tutorials/Atlas.json'\u001b[0m,  \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'epoch_size'\u001b[0m: \u001b[37m500\u001b[0m,                                 \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'merge_annotations'\u001b[0m: \u001b[90m'union'\u001b[0m,                      \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'n_channels'\u001b[0m: \u001b[37m100\u001b[0m,                                 \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'preprocessing'\u001b[0m: \u001b[90m'L1'\u001b[0m,                             \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'transforms_gpu'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[90m'class'\u001b[0m: \u001b[90m'KorniaTransform'\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'degrees'\u001b[0m: \u001b[37m45\u001b[0m,                 \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'p'\u001b[0m: \u001b[37m0.5\u001b[0m,                      \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'padding_mode'\u001b[0m: \u001b[90m'reflection'\u001b[0m,  \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'scale'\u001b[0m: \u001b[1m[\u001b[0m\u001b[37m0.9\u001b[0m, \u001b[37m1.1\u001b[0m\u001b[1m]\u001b[0m,           \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'transformation_name'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'RandomAffine'\u001b[0m,                                               \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'translate'\u001b[0m: \u001b[1m[\u001b[0m\u001b[37m0.0625\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      "\u001b[37m0.0625\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,                                                     \u001b[2m                  \u001b[0m\n",
      "                              \u001b[1m{\u001b[0m\u001b[90m'class'\u001b[0m: \u001b[90m'KorniaTransform'\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'p'\u001b[0m: \u001b[37m0.25\u001b[0m,                     \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'transformation_name'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'RandomHorizontalFlip'\u001b[0m\u001b[1m}\u001b[0m,                                      \u001b[2m                  \u001b[0m\n",
      "                              \u001b[1m{\u001b[0m\u001b[90m'class'\u001b[0m: \u001b[90m'KorniaTransform'\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'p'\u001b[0m: \u001b[37m0.25\u001b[0m,                     \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'transformation_name'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'RandomVerticalFlip'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,                                      \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'label_mapping'\u001b[0m: \u001b[90m'htc.settings_seg>label_mapping'\u001b[0m,           \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'lightning_class'\u001b[0m:                                           \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'htc.models.image.LightningImage>LightningImage'\u001b[0m,             \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'model'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'architecture_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'encoder_name'\u001b[0m:            \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'efficientnet-b5'\u001b[0m,                                            \u001b[2m                  \u001b[0m\n",
      "                                   \u001b[90m'encoder_weights'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'imagenet'\u001b[0m\u001b[1m}\u001b[0m,                                                  \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'architecture_name'\u001b[0m: \u001b[90m'Unet'\u001b[0m,                       \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'model_name'\u001b[0m: \u001b[90m'ModelImage'\u001b[0m\u001b[1m}\u001b[0m,                       \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'optimization'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'lr_scheduler'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'gamma'\u001b[0m: \u001b[37m0.99\u001b[0m, \u001b[90m'name'\u001b[0m:     \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'ExponentialLR'\u001b[0m\u001b[1m}\u001b[0m,                                             \u001b[2m                  \u001b[0m\n",
      "                  \u001b[90m'optimizer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'lr'\u001b[0m: \u001b[37m0.001\u001b[0m,                  \u001b[2m                  \u001b[0m\n",
      "                                \u001b[90m'name'\u001b[0m: \u001b[90m'Adam'\u001b[0m,               \u001b[2m                  \u001b[0m\n",
      "                                \u001b[90m'weight_decay'\u001b[0m: \u001b[37m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'swa_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'annealing_epochs'\u001b[0m: \u001b[37m0\u001b[0m\u001b[1m}\u001b[0m,                       \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'trainer_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'accelerator'\u001b[0m: \u001b[90m'gpu'\u001b[0m,                     \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'devices'\u001b[0m: \u001b[37m1\u001b[0m,                             \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'enable_progress_bar'\u001b[0m: \u001b[3;91mFalse\u001b[0m,             \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'max_epochs'\u001b[0m: \u001b[37m1\u001b[0m,                          \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'precision'\u001b[0m: \u001b[90m'16-mixed'\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'validation'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'checkpoint_metric'\u001b[0m: \u001b[90m'dice_metric'\u001b[0m,           \u001b[2m                  \u001b[0m\n",
      "                \u001b[90m'checkpoint_metric_mode'\u001b[0m: \u001b[90m'class_level'\u001b[0m,      \u001b[2m                  \u001b[0m\n",
      "                \u001b[90m'dataset_index'\u001b[0m: \u001b[37m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m                          \u001b[2m                  \u001b[0m\n",
      "Seed set to 1337\n",
      "\u001b[1m[\u001b[0m\u001b[94mDEBUG\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Used transformations:                             \u001b[2mtransforms.py:124\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;35mToType\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float16\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                                  \u001b[2m                 \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[94mDEBUG\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Used transformations:                             \u001b[2mtransforms.py:124\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;35mToType\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float16\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                                  \u001b[2m                 \u001b[0m\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | model            | ModelImage       | 31.3 M\n",
      "1 | ce_loss_weighted | CrossEntropyLoss | 0     \n",
      "2 | dice_loss        | DiceLoss         | 0     \n",
      "------------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.042   Total estimated model params size (MB)\n",
      "Swapping scheduler `ExponentialLR` for `SWALR`\n",
      "\u001b[1m[\u001b[0m\u001b[94mDEBUG\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Used transformations:                             \u001b[2mtransforms.py:124\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;35mToType\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float32\u001b[1m)\u001b[0m, KorniaTransform\u001b[1m]\u001b[0m                 \u001b[2m                 \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mpy.warnings\u001b[0m\u001b[1m]\u001b[0m                                           \u001b[2mwarnings.py:110\u001b[0m\n",
      "\u001b[35m/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[35m/torch/nn/\u001b[0m\u001b[95mfunctional.py\u001b[0m:\u001b[37m4404\u001b[0m: UserWarning: Default grid_sample   \u001b[2m               \u001b[0m\n",
      "and affine_grid behavior has changed to \u001b[33malign_corners\u001b[0m=\u001b[3;91mFalse\u001b[0m      \u001b[2m               \u001b[0m\n",
      "since \u001b[37m1.3\u001b[0m.\u001b[37m0\u001b[0m. Please specify \u001b[33malign_corners\u001b[0m=\u001b[3;92mTrue\u001b[0m if the old        \u001b[2m               \u001b[0m\n",
      "behavior is desired. See the documentation of grid_sample for    \u001b[2m               \u001b[0m\n",
      "details.                                                         \u001b[2m               \u001b[0m\n",
      "  \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0m                                                 \u001b[2m               \u001b[0m\n",
      "                                                                 \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mpy.warnings\u001b[0m\u001b[1m]\u001b[0m                                           \u001b[2mwarnings.py:110\u001b[0m\n",
      "\u001b[35m/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[35m/torch/nn/\u001b[0m\u001b[95mfunctional.py\u001b[0m:\u001b[37m4343\u001b[0m: UserWarning: Default grid_sample   \u001b[2m               \u001b[0m\n",
      "and affine_grid behavior has changed to \u001b[33malign_corners\u001b[0m=\u001b[3;91mFalse\u001b[0m      \u001b[2m               \u001b[0m\n",
      "since \u001b[37m1.3\u001b[0m.\u001b[37m0\u001b[0m. Please specify \u001b[33malign_corners\u001b[0m=\u001b[3;92mTrue\u001b[0m if the old        \u001b[2m               \u001b[0m\n",
      "behavior is desired. See the documentation of grid_sample for    \u001b[2m               \u001b[0m\n",
      "details.                                                         \u001b[2m               \u001b[0m\n",
      "  \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0m                                                 \u001b[2m               \u001b[0m\n",
      "                                                                 \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Uncaught exception:                          \u001b[2mrun_training.py:384\u001b[0m\n",
      "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:                           \u001b[2m                   \u001b[0m\n",
      "  File \u001b[90m\"/home/lucas/dkfz/htc/htc/models/run_training.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m396\u001b[0m, in \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mfold_trainer.train_fold\u001b[0m\u001b[1m(\u001b[0margs.run_folder, args.fold_name, \u001b[2m                   \u001b[0m\n",
      "args.test, file_log_handler\u001b[1m)\u001b[0m                                 \u001b[2m                   \u001b[0m\n",
      "  File \u001b[90m\"/home/lucas/dkfz/htc/htc/models/run_training.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m67\u001b[0m, in train_fold                                       \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself._train_fold\u001b[0m\u001b[1m(\u001b[0mmodel_dir_tmp, fold_name, *args\u001b[1m)\u001b[0m        \u001b[2m                   \u001b[0m\n",
      "  File \u001b[90m\"/home/lucas/dkfz/htc/htc/models/run_training.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m234\u001b[0m, in _train_fold                                     \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mtrainer.fit\u001b[0m\u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m                                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m544\u001b[0m, in    \u001b[2m                   \u001b[0m\n",
      "fit                                                          \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mcall._call_and_handle_interrupt\u001b[0m\u001b[1m(\u001b[0m                         \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[37m44\u001b[0m, in        \u001b[2m                   \u001b[0m\n",
      "_call_and_handle_interrupt                                   \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mtrainer_fn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                       \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^                       \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m580\u001b[0m, in    \u001b[2m                   \u001b[0m\n",
      "_fit_impl                                                    \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself._run\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[33mckpt_path\u001b[0m=\u001b[35mckpt_path\u001b[0m\u001b[1m)\u001b[0m                    \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m987\u001b[0m, in    \u001b[2m                   \u001b[0m\n",
      "_run                                                         \u001b[2m                   \u001b[0m\n",
      "    results = \u001b[1;35mself._run_stage\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                              \u001b[2m                   \u001b[0m\n",
      "              ^^^^^^^^^^^^^^^^^                              \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m1033\u001b[0m, in   \u001b[2m                   \u001b[0m\n",
      "_run_stage                                                   \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.fit_loop.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/fit_loop.py\"\u001b[0m, line \u001b[37m205\u001b[0m, in run \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                           \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/fit_loop.py\"\u001b[0m, line \u001b[37m363\u001b[0m, in     \u001b[2m                   \u001b[0m\n",
      "advance                                                      \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.epoch_loop.run\u001b[0m\u001b[1m(\u001b[0mself._data_fetcher\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/training_epoch_loop.py\"\u001b[0m, line  \u001b[2m                   \u001b[0m\n",
      "\u001b[37m140\u001b[0m, in run                                                  \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0mdata_fetcher\u001b[1m)\u001b[0m                               \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/training_epoch_loop.py\"\u001b[0m, line  \u001b[2m                   \u001b[0m\n",
      "\u001b[37m250\u001b[0m, in advance                                              \u001b[2m                   \u001b[0m\n",
      "    batch_output =                                           \u001b[2m                   \u001b[0m\n",
      "\u001b[1;35mself.automatic_optimization.run\u001b[0m\u001b[1m(\u001b[0mtrainer.optimizers\u001b[1m[\u001b[0m\u001b[37m0\u001b[0m\u001b[1m]\u001b[0m,       \u001b[2m                   \u001b[0m\n",
      "batch_idx, kwargs\u001b[1m)\u001b[0m                                           \u001b[2m                   \u001b[0m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m190\u001b[0m, in run                                             \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself._optimizer_step\u001b[0m\u001b[1m(\u001b[0mbatch_idx, closure\u001b[1m)\u001b[0m                 \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m268\u001b[0m, in _optimizer_step                                 \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mcall._call_lightning_module_hook\u001b[0m\u001b[1m(\u001b[0m                        \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[37m157\u001b[0m, in       \u001b[2m                   \u001b[0m\n",
      "_call_lightning_module_hook                                  \u001b[2m                   \u001b[0m\n",
      "    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                             \u001b[2m                   \u001b[0m\n",
      "             ^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/core/module.py\"\u001b[0m, line \u001b[37m1303\u001b[0m, in       \u001b[2m                   \u001b[0m\n",
      "optimizer_step                                               \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35moptimizer.step\u001b[0m\u001b[1m(\u001b[0m\u001b[33mclosure\u001b[0m=\u001b[35moptimizer_closure\u001b[0m\u001b[1m)\u001b[0m                \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/core/optimizer.py\"\u001b[0m, line \u001b[37m152\u001b[0m, in     \u001b[2m                   \u001b[0m\n",
      "step                                                         \u001b[2m                   \u001b[0m\n",
      "    step_output =                                            \u001b[2m                   \u001b[0m\n",
      "\u001b[1;35mself._strategy.optimizer_step\u001b[0m\u001b[1m(\u001b[0mself._optimizer, closure,      \u001b[2m                   \u001b[0m\n",
      "**kwargs\u001b[1m)\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^                                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/strategies/strategy.py\"\u001b[0m, line \u001b[37m239\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "in optimizer_step                                            \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself.precision_plugin.optimizer_step\u001b[0m\u001b[1m(\u001b[0moptimizer,   \u001b[2m                   \u001b[0m\n",
      "\u001b[33mmodel\u001b[0m=\u001b[35mmodel\u001b[0m, \u001b[33mclosure\u001b[0m=\u001b[35mclosure\u001b[0m, **kwargs\u001b[1m)\u001b[0m                      \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                       \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/plugins/precision/amp.py\"\u001b[0m, line \u001b[37m80\u001b[0m,  \u001b[2m                   \u001b[0m\n",
      "in optimizer_step                                            \u001b[2m                   \u001b[0m\n",
      "    closure_result = \u001b[1;35mclosure\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                               \u001b[2m                   \u001b[0m\n",
      "                     ^^^^^^^^^                               \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m144\u001b[0m, in __call__                                        \u001b[2m                   \u001b[0m\n",
      "    self._result = \u001b[1;35mself.closure\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m             \u001b[2m                   \u001b[0m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/utils/_contextlib.py\"\u001b[0m, line \u001b[37m115\u001b[0m, in              \u001b[2m                   \u001b[0m\n",
      "decorate_context                                             \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mfunc\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                             \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m129\u001b[0m, in closure                                         \u001b[2m                   \u001b[0m\n",
      "    step_output = \u001b[1;35mself._step_fn\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m                   \u001b[0m\n",
      "                  ^^^^^^^^^^^^^^^                            \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m318\u001b[0m, in _training_step                                  \u001b[2m                   \u001b[0m\n",
      "    training_step_output = \u001b[1;35mcall._call_strategy_hook\u001b[0m\u001b[1m(\u001b[0mtrainer, \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"training_step\"\u001b[0m, *\u001b[1;35mkwargs.values\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                           \u001b[2m                   \u001b[0m\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                          \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[37m309\u001b[0m, in       \u001b[2m                   \u001b[0m\n",
      "_call_strategy_hook                                          \u001b[2m                   \u001b[0m\n",
      "    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                             \u001b[2m                   \u001b[0m\n",
      "             ^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/strategies/strategy.py\"\u001b[0m, line \u001b[37m391\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "in training_step                                             \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself.lightning_module.training_step\u001b[0m\u001b[1m(\u001b[0m*args,        \u001b[2m                   \u001b[0m\n",
      "**kwargs\u001b[1m)\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^                                                          \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\"\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m120\u001b[0m, in training_step                                   \u001b[2m                   \u001b[0m\n",
      "    predictions = \u001b[1;35mself\u001b[0m\u001b[1m(\u001b[0mbatch\u001b[1m)\u001b[0m                                \u001b[2m                   \u001b[0m\n",
      "                  ^^^^^^^^^^^                                \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\"\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m105\u001b[0m, in forward                                         \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself.model\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^                                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1582\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    result = \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                   \u001b[2m                   \u001b[0m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/dkfz/htc/htc/models/image/ModelImage.py\"\u001b[0m, line  \u001b[2m                   \u001b[0m\n",
      "\u001b[37m35\u001b[0m, in forward                                               \u001b[2m                   \u001b[0m\n",
      "    x = \u001b[1;35mself.architecture\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                                 \u001b[2m                   \u001b[0m\n",
      "        ^^^^^^^^^^^^^^^^^^^^                                 \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/segmentation_models_pytorch/base/model.py\"\u001b[0m, line \u001b[37m29\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "in forward                                                   \u001b[2m                   \u001b[0m\n",
      "    features = \u001b[1;35mself.encoder\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                               \u001b[2m                   \u001b[0m\n",
      "               ^^^^^^^^^^^^^^^                               \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/segmentation_models_pytorch/encoders/efficientnet.py\"\u001b[0m, \u001b[2m                   \u001b[0m\n",
      " line \u001b[37m73\u001b[0m, in forward                                         \u001b[2m                   \u001b[0m\n",
      "    x = \u001b[1;35mmodule\u001b[0m\u001b[1m(\u001b[0mx, drop_connect\u001b[1m)\u001b[0m                              \u001b[2m                   \u001b[0m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^                              \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/efficientnet_pytorch/model.py\"\u001b[0m, line \u001b[37m111\u001b[0m, in forward   \u001b[2m                   \u001b[0m\n",
      "    x = \u001b[1;35mself._swish\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                                       \u001b[2m                   \u001b[0m\n",
      "        ^^^^^^^^^^^^^^                                       \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/efficientnet_pytorch/utils.py\"\u001b[0m, line \u001b[37m80\u001b[0m, in forward    \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mSwishImplementation.apply\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                      \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/autograd/function.py\"\u001b[0m, line \u001b[37m598\u001b[0m, in apply        \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.apply\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m  # type: ignore    \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                    \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/efficientnet_pytorch/utils.py\"\u001b[0m, line \u001b[37m67\u001b[0m, in forward    \u001b[2m                   \u001b[0m\n",
      "    result = i * \u001b[1;35mtorch.sigmoid\u001b[0m\u001b[1m(\u001b[0mi\u001b[1m)\u001b[0m                            \u001b[2m                   \u001b[0m\n",
      "                 ^^^^^^^^^^^^^^^^                            \u001b[2m                   \u001b[0m\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to    \u001b[2m                   \u001b[0m\n",
      "allocate \u001b[37m20.00\u001b[0m MiB. GPU                                      \u001b[2m                   \u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/run_training.py\", line 396, in <module>\n",
      "    fold_trainer.train_fold(args.run_folder, args.fold_name, args.test, file_log_handler)\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/run_training.py\", line 67, in train_fold\n",
      "    self._train_fold(model_dir_tmp, fold_name, *args)\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/run_training.py\", line 234, in _train_fold\n",
      "    trainer.fit(module)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 987, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1033, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1303, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 152, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 80, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 129, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 318, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\", line 120, in training_step\n",
      "    predictions = self(batch)\n",
      "                  ^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\", line 105, in forward\n",
      "    return self.model(x)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/image/ModelImage.py\", line 35, in forward\n",
      "    x = self.architecture(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/segmentation_models_pytorch/base/model.py\", line 29, in forward\n",
      "    features = self.encoder(x)\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/efficientnet.py\", line 73, in forward\n",
      "    x = module(x, drop_connect)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/efficientnet_pytorch/model.py\", line 111, in forward\n",
      "    x = self._swish(x)\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/efficientnet_pytorch/utils.py\", line 80, in forward\n",
      "    return SwishImplementation.apply(x)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/autograd/function.py\", line 598, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/efficientnet_pytorch/utils.py\", line 67, in forward\n",
      "    result = i * torch.sigmoid(i)\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \n",
      "\u001b[1m[\u001b[0m\u001b[1;31mERROR\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Training of the fold fold_1 was not successful  \u001b[2mrun_training.py:304\u001b[0m\n",
      "\u001b[1m(\u001b[0m\u001b[33mreturncode\u001b[0m=\u001b[37m1\u001b[0m                                                \u001b[2m                   \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Starting training of the fold fold_2 \u001b[1m[\u001b[0m\u001b[37m2\u001b[0m/\u001b[37m2\u001b[0m\u001b[1m]\u001b[0m       \u001b[2mrun_training.py:301\u001b[0m\n",
      "_build_cache was acessed\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m The environment variable                          \u001b[2mDatasets.py:125\u001b[0m\n",
      "PATH_Tivita_Cat_atlas_kidney_nativ was set to                    \u001b[2m               \u001b[0m\n",
      "\u001b[35m/home/lucas/dkfz/htc/tests/test_31may/\u001b[0m\u001b[95mCat_atlas_kidney_nativ\u001b[0m but \u001b[2m               \u001b[0m\n",
      "the path does not exist                                          \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m The following config will be used for training:   \u001b[2mrun_training.py:81\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m \u001b[1m{\u001b[0m\u001b[90m'config_name'\u001b[0m: \u001b[90m'Atlas_config'\u001b[0m,                   \u001b[2mrun_training.py:82\u001b[0m\n",
      " \u001b[90m'dataloader_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'batch_size'\u001b[0m: \u001b[37m5\u001b[0m, \u001b[90m'num_workers'\u001b[0m: \u001b[37m1\u001b[0m\u001b[1m}\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'input'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'annotation_name'\u001b[0m: \u001b[1m[\u001b[0m\u001b[90m'\u001b[0m\u001b[36mpolygon#annotator1\u001b[0m\u001b[90m'\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'\u001b[0m\u001b[36mpolygon#annotator2\u001b[0m\u001b[90m'\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'\u001b[0m\u001b[36mpolygon#annotator3\u001b[0m\u001b[90m'\u001b[0m\u001b[1m]\u001b[0m,         \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'data_spec'\u001b[0m:                                       \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'/home/lucas/dkfz/htc/tutorials/Atlas_tutorials/Atlas.json'\u001b[0m,  \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'epoch_size'\u001b[0m: \u001b[37m500\u001b[0m,                                 \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'merge_annotations'\u001b[0m: \u001b[90m'union'\u001b[0m,                      \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'n_channels'\u001b[0m: \u001b[37m100\u001b[0m,                                 \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'preprocessing'\u001b[0m: \u001b[90m'L1'\u001b[0m,                             \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'transforms_gpu'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[90m'class'\u001b[0m: \u001b[90m'KorniaTransform'\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'degrees'\u001b[0m: \u001b[37m45\u001b[0m,                 \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'p'\u001b[0m: \u001b[37m0.5\u001b[0m,                      \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'padding_mode'\u001b[0m: \u001b[90m'reflection'\u001b[0m,  \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'scale'\u001b[0m: \u001b[1m[\u001b[0m\u001b[37m0.9\u001b[0m, \u001b[37m1.1\u001b[0m\u001b[1m]\u001b[0m,           \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'transformation_name'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'RandomAffine'\u001b[0m,                                               \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'translate'\u001b[0m: \u001b[1m[\u001b[0m\u001b[37m0.0625\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      "\u001b[37m0.0625\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,                                                     \u001b[2m                  \u001b[0m\n",
      "                              \u001b[1m{\u001b[0m\u001b[90m'class'\u001b[0m: \u001b[90m'KorniaTransform'\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'p'\u001b[0m: \u001b[37m0.25\u001b[0m,                     \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'transformation_name'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'RandomHorizontalFlip'\u001b[0m\u001b[1m}\u001b[0m,                                      \u001b[2m                  \u001b[0m\n",
      "                              \u001b[1m{\u001b[0m\u001b[90m'class'\u001b[0m: \u001b[90m'KorniaTransform'\u001b[0m,    \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'p'\u001b[0m: \u001b[37m0.25\u001b[0m,                     \u001b[2m                  \u001b[0m\n",
      "                               \u001b[90m'transformation_name'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'RandomVerticalFlip'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m,                                      \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'label_mapping'\u001b[0m: \u001b[90m'htc.settings_seg>label_mapping'\u001b[0m,           \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'lightning_class'\u001b[0m:                                           \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'htc.models.image.LightningImage>LightningImage'\u001b[0m,             \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'model'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'architecture_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'encoder_name'\u001b[0m:            \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'efficientnet-b5'\u001b[0m,                                            \u001b[2m                  \u001b[0m\n",
      "                                   \u001b[90m'encoder_weights'\u001b[0m:         \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'imagenet'\u001b[0m\u001b[1m}\u001b[0m,                                                  \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'architecture_name'\u001b[0m: \u001b[90m'Unet'\u001b[0m,                       \u001b[2m                  \u001b[0m\n",
      "           \u001b[90m'model_name'\u001b[0m: \u001b[90m'ModelImage'\u001b[0m\u001b[1m}\u001b[0m,                       \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'optimization'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'lr_scheduler'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'gamma'\u001b[0m: \u001b[37m0.99\u001b[0m, \u001b[90m'name'\u001b[0m:     \u001b[2m                  \u001b[0m\n",
      "\u001b[90m'ExponentialLR'\u001b[0m\u001b[1m}\u001b[0m,                                             \u001b[2m                  \u001b[0m\n",
      "                  \u001b[90m'optimizer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'lr'\u001b[0m: \u001b[37m0.001\u001b[0m,                  \u001b[2m                  \u001b[0m\n",
      "                                \u001b[90m'name'\u001b[0m: \u001b[90m'Adam'\u001b[0m,               \u001b[2m                  \u001b[0m\n",
      "                                \u001b[90m'weight_decay'\u001b[0m: \u001b[37m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,          \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'swa_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'annealing_epochs'\u001b[0m: \u001b[37m0\u001b[0m\u001b[1m}\u001b[0m,                       \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'trainer_kwargs'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'accelerator'\u001b[0m: \u001b[90m'gpu'\u001b[0m,                     \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'devices'\u001b[0m: \u001b[37m1\u001b[0m,                             \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'enable_progress_bar'\u001b[0m: \u001b[3;91mFalse\u001b[0m,             \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'max_epochs'\u001b[0m: \u001b[37m1\u001b[0m,                          \u001b[2m                  \u001b[0m\n",
      "                    \u001b[90m'precision'\u001b[0m: \u001b[90m'16-mixed'\u001b[0m\u001b[1m}\u001b[0m,                 \u001b[2m                  \u001b[0m\n",
      " \u001b[90m'validation'\u001b[0m: \u001b[1m{\u001b[0m\u001b[90m'checkpoint_metric'\u001b[0m: \u001b[90m'dice_metric'\u001b[0m,           \u001b[2m                  \u001b[0m\n",
      "                \u001b[90m'checkpoint_metric_mode'\u001b[0m: \u001b[90m'class_level'\u001b[0m,      \u001b[2m                  \u001b[0m\n",
      "                \u001b[90m'dataset_index'\u001b[0m: \u001b[37m0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m                          \u001b[2m                  \u001b[0m\n",
      "Seed set to 1337\n",
      "\u001b[1m[\u001b[0m\u001b[94mDEBUG\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Used transformations:                             \u001b[2mtransforms.py:124\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;35mToType\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float16\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                                  \u001b[2m                 \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[94mDEBUG\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Used transformations:                             \u001b[2mtransforms.py:124\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;35mToType\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float16\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m                                  \u001b[2m                 \u001b[0m\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | model            | ModelImage       | 31.3 M\n",
      "1 | ce_loss_weighted | CrossEntropyLoss | 0     \n",
      "2 | dice_loss        | DiceLoss         | 0     \n",
      "------------------------------------------------------\n",
      "31.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.3 M    Total params\n",
      "125.042   Total estimated model params size (MB)\n",
      "Swapping scheduler `ExponentialLR` for `SWALR`\n",
      "\u001b[1m[\u001b[0m\u001b[94mDEBUG\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Used transformations:                             \u001b[2mtransforms.py:124\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;35mToType\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mtorch\u001b[0m.float32\u001b[1m)\u001b[0m, KorniaTransform\u001b[1m]\u001b[0m                 \u001b[2m                 \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mpy.warnings\u001b[0m\u001b[1m]\u001b[0m                                           \u001b[2mwarnings.py:110\u001b[0m\n",
      "\u001b[35m/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[35m/torch/nn/\u001b[0m\u001b[95mfunctional.py\u001b[0m:\u001b[37m4404\u001b[0m: UserWarning: Default grid_sample   \u001b[2m               \u001b[0m\n",
      "and affine_grid behavior has changed to \u001b[33malign_corners\u001b[0m=\u001b[3;91mFalse\u001b[0m      \u001b[2m               \u001b[0m\n",
      "since \u001b[37m1.3\u001b[0m.\u001b[37m0\u001b[0m. Please specify \u001b[33malign_corners\u001b[0m=\u001b[3;92mTrue\u001b[0m if the old        \u001b[2m               \u001b[0m\n",
      "behavior is desired. See the documentation of grid_sample for    \u001b[2m               \u001b[0m\n",
      "details.                                                         \u001b[2m               \u001b[0m\n",
      "  \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0m                                                 \u001b[2m               \u001b[0m\n",
      "                                                                 \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mpy.warnings\u001b[0m\u001b[1m]\u001b[0m                                           \u001b[2mwarnings.py:110\u001b[0m\n",
      "\u001b[35m/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages\u001b[0m \u001b[2m               \u001b[0m\n",
      "\u001b[35m/torch/nn/\u001b[0m\u001b[95mfunctional.py\u001b[0m:\u001b[37m4343\u001b[0m: UserWarning: Default grid_sample   \u001b[2m               \u001b[0m\n",
      "and affine_grid behavior has changed to \u001b[33malign_corners\u001b[0m=\u001b[3;91mFalse\u001b[0m      \u001b[2m               \u001b[0m\n",
      "since \u001b[37m1.3\u001b[0m.\u001b[37m0\u001b[0m. Please specify \u001b[33malign_corners\u001b[0m=\u001b[3;92mTrue\u001b[0m if the old        \u001b[2m               \u001b[0m\n",
      "behavior is desired. See the documentation of grid_sample for    \u001b[2m               \u001b[0m\n",
      "details.                                                         \u001b[2m               \u001b[0m\n",
      "  \u001b[1;35mwarnings.warn\u001b[0m\u001b[1m(\u001b[0m                                                 \u001b[2m               \u001b[0m\n",
      "                                                                 \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[33mWARNING\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m The model ModelImage expects L1 normalized input  \u001b[2mHTCModel.py:220\u001b[0m\n",
      "but the features \u001b[1m(\u001b[0mfeatures.shape = \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[37m5\u001b[0m, \u001b[37m100\u001b[0m, \u001b[37m480\u001b[0m,      \u001b[2m               \u001b[0m\n",
      "\u001b[37m640\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m do not seem to be L1 normalized:                          \u001b[2m               \u001b[0m\n",
      "average per pixel = \u001b[37m0.9958443641662598\u001b[0m                           \u001b[2m               \u001b[0m\n",
      "standard deviation per pixel = \u001b[37m0.023611782118678093\u001b[0m              \u001b[2m               \u001b[0m\n",
      "This check is only performed for the first batch.                \u001b[2m               \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;7;31mCRITICAL\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Uncaught exception:                          \u001b[2mrun_training.py:384\u001b[0m\n",
      "Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:                           \u001b[2m                   \u001b[0m\n",
      "  File \u001b[90m\"/home/lucas/dkfz/htc/htc/models/run_training.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m396\u001b[0m, in \u001b[1m<\u001b[0m\u001b[1;95mmodule\u001b[0m\u001b[1m>\u001b[0m                                        \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mfold_trainer.train_fold\u001b[0m\u001b[1m(\u001b[0margs.run_folder, args.fold_name, \u001b[2m                   \u001b[0m\n",
      "args.test, file_log_handler\u001b[1m)\u001b[0m                                 \u001b[2m                   \u001b[0m\n",
      "  File \u001b[90m\"/home/lucas/dkfz/htc/htc/models/run_training.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m67\u001b[0m, in train_fold                                       \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself._train_fold\u001b[0m\u001b[1m(\u001b[0mmodel_dir_tmp, fold_name, *args\u001b[1m)\u001b[0m        \u001b[2m                   \u001b[0m\n",
      "  File \u001b[90m\"/home/lucas/dkfz/htc/htc/models/run_training.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m234\u001b[0m, in _train_fold                                     \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mtrainer.fit\u001b[0m\u001b[1m(\u001b[0mmodule\u001b[1m)\u001b[0m                                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m544\u001b[0m, in    \u001b[2m                   \u001b[0m\n",
      "fit                                                          \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mcall._call_and_handle_interrupt\u001b[0m\u001b[1m(\u001b[0m                         \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[37m44\u001b[0m, in        \u001b[2m                   \u001b[0m\n",
      "_call_and_handle_interrupt                                   \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mtrainer_fn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                       \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^                       \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m580\u001b[0m, in    \u001b[2m                   \u001b[0m\n",
      "_fit_impl                                                    \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself._run\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[33mckpt_path\u001b[0m=\u001b[35mckpt_path\u001b[0m\u001b[1m)\u001b[0m                    \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m987\u001b[0m, in    \u001b[2m                   \u001b[0m\n",
      "_run                                                         \u001b[2m                   \u001b[0m\n",
      "    results = \u001b[1;35mself._run_stage\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                              \u001b[2m                   \u001b[0m\n",
      "              ^^^^^^^^^^^^^^^^^                              \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/trainer.py\"\u001b[0m, line \u001b[37m1033\u001b[0m, in   \u001b[2m                   \u001b[0m\n",
      "_run_stage                                                   \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.fit_loop.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/fit_loop.py\"\u001b[0m, line \u001b[37m205\u001b[0m, in run \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                                           \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/fit_loop.py\"\u001b[0m, line \u001b[37m363\u001b[0m, in     \u001b[2m                   \u001b[0m\n",
      "advance                                                      \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.epoch_loop.run\u001b[0m\u001b[1m(\u001b[0mself._data_fetcher\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/training_epoch_loop.py\"\u001b[0m, line  \u001b[2m                   \u001b[0m\n",
      "\u001b[37m140\u001b[0m, in run                                                  \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself.advance\u001b[0m\u001b[1m(\u001b[0mdata_fetcher\u001b[1m)\u001b[0m                               \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/training_epoch_loop.py\"\u001b[0m, line  \u001b[2m                   \u001b[0m\n",
      "\u001b[37m250\u001b[0m, in advance                                              \u001b[2m                   \u001b[0m\n",
      "    batch_output =                                           \u001b[2m                   \u001b[0m\n",
      "\u001b[1;35mself.automatic_optimization.run\u001b[0m\u001b[1m(\u001b[0mtrainer.optimizers\u001b[1m[\u001b[0m\u001b[37m0\u001b[0m\u001b[1m]\u001b[0m,       \u001b[2m                   \u001b[0m\n",
      "batch_idx, kwargs\u001b[1m)\u001b[0m                                           \u001b[2m                   \u001b[0m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m190\u001b[0m, in run                                             \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mself._optimizer_step\u001b[0m\u001b[1m(\u001b[0mbatch_idx, closure\u001b[1m)\u001b[0m                 \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m268\u001b[0m, in _optimizer_step                                 \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35mcall._call_lightning_module_hook\u001b[0m\u001b[1m(\u001b[0m                        \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[37m157\u001b[0m, in       \u001b[2m                   \u001b[0m\n",
      "_call_lightning_module_hook                                  \u001b[2m                   \u001b[0m\n",
      "    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                             \u001b[2m                   \u001b[0m\n",
      "             ^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/core/module.py\"\u001b[0m, line \u001b[37m1303\u001b[0m, in       \u001b[2m                   \u001b[0m\n",
      "optimizer_step                                               \u001b[2m                   \u001b[0m\n",
      "    \u001b[1;35moptimizer.step\u001b[0m\u001b[1m(\u001b[0m\u001b[33mclosure\u001b[0m=\u001b[35moptimizer_closure\u001b[0m\u001b[1m)\u001b[0m                \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/core/optimizer.py\"\u001b[0m, line \u001b[37m152\u001b[0m, in     \u001b[2m                   \u001b[0m\n",
      "step                                                         \u001b[2m                   \u001b[0m\n",
      "    step_output =                                            \u001b[2m                   \u001b[0m\n",
      "\u001b[1;35mself._strategy.optimizer_step\u001b[0m\u001b[1m(\u001b[0mself._optimizer, closure,      \u001b[2m                   \u001b[0m\n",
      "**kwargs\u001b[1m)\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^                                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/strategies/strategy.py\"\u001b[0m, line \u001b[37m239\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "in optimizer_step                                            \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself.precision_plugin.optimizer_step\u001b[0m\u001b[1m(\u001b[0moptimizer,   \u001b[2m                   \u001b[0m\n",
      "\u001b[33mmodel\u001b[0m=\u001b[35mmodel\u001b[0m, \u001b[33mclosure\u001b[0m=\u001b[35mclosure\u001b[0m, **kwargs\u001b[1m)\u001b[0m                      \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                       \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/plugins/precision/amp.py\"\u001b[0m, line \u001b[37m80\u001b[0m,  \u001b[2m                   \u001b[0m\n",
      "in optimizer_step                                            \u001b[2m                   \u001b[0m\n",
      "    closure_result = \u001b[1;35mclosure\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                               \u001b[2m                   \u001b[0m\n",
      "                     ^^^^^^^^^                               \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m144\u001b[0m, in __call__                                        \u001b[2m                   \u001b[0m\n",
      "    self._result = \u001b[1;35mself.closure\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m             \u001b[2m                   \u001b[0m\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/utils/_contextlib.py\"\u001b[0m, line \u001b[37m115\u001b[0m, in              \u001b[2m                   \u001b[0m\n",
      "decorate_context                                             \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mfunc\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                             \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m129\u001b[0m, in closure                                         \u001b[2m                   \u001b[0m\n",
      "    step_output = \u001b[1;35mself._step_fn\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m                   \u001b[0m\n",
      "                  ^^^^^^^^^^^^^^^                            \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/loops/optimization/automatic.py\"\u001b[0m,    \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m318\u001b[0m, in _training_step                                  \u001b[2m                   \u001b[0m\n",
      "    training_step_output = \u001b[1;35mcall._call_strategy_hook\u001b[0m\u001b[1m(\u001b[0mtrainer, \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"training_step\"\u001b[0m, *\u001b[1;35mkwargs.values\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m                           \u001b[2m                   \u001b[0m\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                          \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/trainer/call.py\"\u001b[0m, line \u001b[37m309\u001b[0m, in       \u001b[2m                   \u001b[0m\n",
      "_call_strategy_hook                                          \u001b[2m                   \u001b[0m\n",
      "    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                             \u001b[2m                   \u001b[0m\n",
      "             ^^^^^^^^^^^^^^^^^^^                             \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/lightning/pytorch/strategies/strategy.py\"\u001b[0m, line \u001b[37m391\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "in training_step                                             \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself.lightning_module.training_step\u001b[0m\u001b[1m(\u001b[0m*args,        \u001b[2m                   \u001b[0m\n",
      "**kwargs\u001b[1m)\u001b[0m                                                    \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \u001b[2m                   \u001b[0m\n",
      "^^^                                                          \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\"\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m120\u001b[0m, in training_step                                   \u001b[2m                   \u001b[0m\n",
      "    predictions = \u001b[1;35mself\u001b[0m\u001b[1m(\u001b[0mbatch\u001b[1m)\u001b[0m                                \u001b[2m                   \u001b[0m\n",
      "                  ^^^^^^^^^^^                                \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\"\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "line \u001b[37m105\u001b[0m, in forward                                         \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself.model\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^                                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1582\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    result = \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                   \u001b[2m                   \u001b[0m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                   \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/dkfz/htc/htc/models/image/ModelImage.py\"\u001b[0m, line  \u001b[2m                   \u001b[0m\n",
      "\u001b[37m35\u001b[0m, in forward                                               \u001b[2m                   \u001b[0m\n",
      "    x = \u001b[1;35mself.architecture\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                                 \u001b[2m                   \u001b[0m\n",
      "        ^^^^^^^^^^^^^^^^^^^^                                 \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/segmentation_models_pytorch/base/model.py\"\u001b[0m, line \u001b[37m29\u001b[0m,   \u001b[2m                   \u001b[0m\n",
      "in forward                                                   \u001b[2m                   \u001b[0m\n",
      "    features = \u001b[1;35mself.encoder\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                               \u001b[2m                   \u001b[0m\n",
      "               ^^^^^^^^^^^^^^^                               \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/segmentation_models_pytorch/encoders/efficientnet.py\"\u001b[0m, \u001b[2m                   \u001b[0m\n",
      " line \u001b[37m73\u001b[0m, in forward                                         \u001b[2m                   \u001b[0m\n",
      "    x = \u001b[1;35mmodule\u001b[0m\u001b[1m(\u001b[0mx, drop_connect\u001b[1m)\u001b[0m                              \u001b[2m                   \u001b[0m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^                              \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/efficientnet_pytorch/model.py\"\u001b[0m, line \u001b[37m111\u001b[0m, in forward   \u001b[2m                   \u001b[0m\n",
      "    x = \u001b[1;35mself._swish\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                                       \u001b[2m                   \u001b[0m\n",
      "        ^^^^^^^^^^^^^^                                       \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1532\u001b[0m, in             \u001b[2m                   \u001b[0m\n",
      "_wrapped_call_impl                                           \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mself._call_impl\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                  \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                  \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[37m1541\u001b[0m, in _call_impl  \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m                     \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                     \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/efficientnet_pytorch/utils.py\"\u001b[0m, line \u001b[37m80\u001b[0m, in forward    \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35mSwishImplementation.apply\u001b[0m\u001b[1m(\u001b[0mx\u001b[1m)\u001b[0m                      \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^                      \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/torch/autograd/function.py\"\u001b[0m, line \u001b[37m598\u001b[0m, in apply        \u001b[2m                   \u001b[0m\n",
      "    return \u001b[1;35msuper\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1;35m.apply\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m  # type: ignore    \u001b[2m                   \u001b[0m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                    \u001b[2m                   \u001b[0m\n",
      "  File                                                       \u001b[2m                   \u001b[0m\n",
      "\u001b[90m\"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-pac\u001b[0m \u001b[2m                   \u001b[0m\n",
      "\u001b[90mkages/efficientnet_pytorch/utils.py\"\u001b[0m, line \u001b[37m67\u001b[0m, in forward    \u001b[2m                   \u001b[0m\n",
      "    result = i * \u001b[1;35mtorch.sigmoid\u001b[0m\u001b[1m(\u001b[0mi\u001b[1m)\u001b[0m                            \u001b[2m                   \u001b[0m\n",
      "                 ^^^^^^^^^^^^^^^^                            \u001b[2m                   \u001b[0m\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to    \u001b[2m                   \u001b[0m\n",
      "allocate \u001b[37m20.00\u001b[0m MiB. GPU                                      \u001b[2m                   \u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/run_training.py\", line 396, in <module>\n",
      "    fold_trainer.train_fold(args.run_folder, args.fold_name, args.test, file_log_handler)\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/run_training.py\", line 67, in train_fold\n",
      "    self._train_fold(model_dir_tmp, fold_name, *args)\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/run_training.py\", line 234, in _train_fold\n",
      "    trainer.fit(module)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 44, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 987, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1033, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 205, in run\n",
      "    self.advance()\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 363, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 140, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 250, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 190, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 268, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1303, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 152, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 239, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/amp.py\", line 80, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 144, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 129, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 318, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 391, in training_step\n",
      "    return self.lightning_module.training_step(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\", line 120, in training_step\n",
      "    predictions = self(batch)\n",
      "                  ^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/image/LightningImage.py\", line 105, in forward\n",
      "    return self.model(x)\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1582, in _call_impl\n",
      "    result = forward_call(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/dkfz/htc/htc/models/image/ModelImage.py\", line 35, in forward\n",
      "    x = self.architecture(x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/segmentation_models_pytorch/base/model.py\", line 29, in forward\n",
      "    features = self.encoder(x)\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/efficientnet.py\", line 73, in forward\n",
      "    x = module(x, drop_connect)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/efficientnet_pytorch/model.py\", line 111, in forward\n",
      "    x = self._swish(x)\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/efficientnet_pytorch/utils.py\", line 80, in forward\n",
      "    return SwishImplementation.apply(x)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/torch/autograd/function.py\", line 598, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/miniconda3/envs/htc-dev/lib/python3.11/site-packages/efficientnet_pytorch/utils.py\", line 67, in forward\n",
      "    result = i * torch.sigmoid(i)\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU \n",
      "\u001b[1m[\u001b[0m\u001b[1;31mERROR\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Training of the fold fold_2 was not successful  \u001b[2mrun_training.py:304\u001b[0m\n",
      "\u001b[1m(\u001b[0m\u001b[33mreturncode\u001b[0m=\u001b[37m1\u001b[0m                                                \u001b[2m                   \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[1;31mERROR\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Some folds were not successful \u001b[1m(\u001b[0msee error       \u001b[2mrun_training.py:308\u001b[0m\n",
      "messages above\u001b[1m)\u001b[0m                                              \u001b[2m                   \u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[32mINFO\u001b[0m\u001b[1m]\u001b[0m\u001b[1m[\u001b[0m\u001b[3mhtc\u001b[0m\u001b[1m]\u001b[0m Training time for the all folds: \u001b[37m0\u001b[0m minutes and   \u001b[2mrun_training.py:310\u001b[0m\n",
      "\u001b[37m37.13\u001b[0m seconds                                                \u001b[2m                   \u001b[0m\n",
      "After starting training:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "# Retrieve GPU memory information\n",
    "allocated_memory, total_memory = torch.cuda.mem_get_info()\n",
    "print(f\"Allocated Memory: {allocated_memory / (1024 ** 2):.2f} MB\")\n",
    "print(f\"Total Memory: {total_memory / (1024 ** 2):.2f} MB\")\n",
    "\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "!htc training --model image --config $config_path\n",
    "print(\"After starting training:\")\n",
    "assert _exit_code == 0, \"Training was not successful\"  # noqa: F821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 10 15:21:49 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.104      Driver Version: 528.79       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   56C    P8     3W /  80W |     68MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A        29      G   /Xwayland                       N/A      |\n",
      "|    0   N/A  N/A    149264      C   /python3.11                     N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version: 12.1\n",
      "PyTorch CUDA Support: True\n",
      "Number of GPUs: 1\n",
      "\n",
      "GPU 0: NVIDIA GeForce GTX 1660 Ti\n",
      "  Total Memory: 6.00 GB\n",
      "  Allocated Memory: 0.00 MB\n",
      "  Cached Memory: 0.00 MB\n",
      "  Current Memory Usage: 0.00 MB\n",
      "  Peak Memory Usage: 0.00 MB\n",
      "  Free Memory: 6143.69 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def print_gpu_info():\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"PyTorch CUDA Support: {torch.cuda.is_available()}\")\n",
    "        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"  Total Memory: {torch.cuda.get_device_properties(i).total_memory / 1024 ** 3:.2f} GB\")\n",
    "            print(f\"  Allocated Memory: {torch.cuda.memory_allocated(i) / 1024 ** 2:.2f} MB\")\n",
    "            print(f\"  Cached Memory: {torch.cuda.memory_reserved(i) / 1024 ** 2:.2f} MB\")\n",
    "            print(f\"  Current Memory Usage: {torch.cuda.memory_allocated(i) / 1024 ** 2:.2f} MB\")\n",
    "            print(f\"  Peak Memory Usage: {torch.cuda.max_memory_allocated(i) / 1024 ** 2:.2f} MB\")\n",
    "            print(f\"  Free Memory: {(torch.cuda.get_device_properties(i).total_memory - torch.cuda.memory_allocated(i)) / 1024 ** 2:.2f} MB\")\n",
    "\n",
    "print_gpu_info()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "htc-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
